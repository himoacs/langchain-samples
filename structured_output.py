from dotenv import load_dotenv
from langchain_ollama import ChatOllama
from typing import List
from pydantic import BaseModel, Field
from langchain_tavily import TavilySearch
from langchain.agents import create_agent
import os

load_dotenv()

class Source(BaseModel):
    """Scheme for a source used by the agent"""

    url: str = Field(description="The URL of the source")

class AgentResponse(BaseModel):
    """Schema for agent response with answers and sources"""

    answer: str = Field(description="The answer generated by the agent")
    sources: List[Source] = Field(default_factory=list, description="The list of sources used by the agent to generate the answer")


llm = ChatOllama(model="gpt-oss:20b", temperature=0)
tools = [TavilySearch()]
agent = create_agent(
                model=llm, 
                tools=tools, 
                response_format=AgentResponse
        )


def main():
    
    result = agent.invoke(
        {
            "messages": [
                {
                    "role": "user",
                    "content": "search for 3 job postings for an ai engineer using langchain in the bay area on linkedin and list their details along with sources",
                }
            ]
        }
    )
    structured = result.get("structured_response", None)
    print(structured if structured is not None else print(result))


if __name__ == "__main__":
    main()